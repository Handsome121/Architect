# Kafka

 Kafka是由[Apache软件基金会](https://baike.baidu.com/item/Apache软件基金会)开发的一个开源流处理平台，由[Scala](https://baike.baidu.com/item/Scala/2462287)和[Java](https://baike.baidu.com/item/Java/85979)编写。Kafka是一种高吞吐量的[分布式](https://baike.baidu.com/item/分布式/19276232)发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像[Hadoop](https://baike.baidu.com/item/Hadoop)一样的[日志](https://baike.baidu.com/item/日志/2769135)数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过[Hadoop](https://baike.baidu.com/item/Hadoop)的并行加载机制来统一线上和离线的消息处理，也是为了通过[集群](https://baike.baidu.com/item/集群/5486962)来提供实时的消息。 

#### 主要特性

Kafka 是一种高吞吐量 的分布式发布订阅消息系统，有如下特性：

通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。

高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。

支持通过Kafka服务器和消费机集群来分区消息。

支持[Hadoop](https://baike.baidu.com/item/Hadoop)并行数据加载。 

Kafka通过官网发布了最新版本2.5.0 

kafka面试题

#### 1.Kafka 的设计时什么样的呢？

 Kafka 将消息以 topic 为单位进行归纳， 将向 Kafka topic 发布消息的程序成为 producers ， 将预订 topics 并消费消息的程序成为 consumer， Kafka 以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 broker. producers 通过网络将消息发送到 Kafka 集群，集群向消费者提供消息  

####  2.数据传输的事物定义有哪三种？

数据传输的事务定义通常有以下三种级别：

1、最多一次：消息不会被重复发送，最多被传输一次，但也有可能一次不传输。

2、 最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输 。

3、 精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而 且仅仅被传输一次，这是大家所期望的 

#### 3. Kafka 判断一个节点是否还活着有那两个条件？  

1、节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接 

2、如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久 

#### 4.producer 是否直接将数据发送到 broker 的 leader(主节点)？

producer 直接将数据发送到 broker 的 leader(主节点)，不需要在多个节点进行分发，为了 帮助 producer 做到这点，所有的 Kafka 节点都可以及时的告知:哪些节点是活动的，目标 topic 目标分区的 leader 在哪。这样 producer 就可以直接将消息发送到目的地了 

#### 5.Kafka consumer 是否可以消费指定分区消息？

 kafka consumer 消费消息时，向 broker 发出"fetch"请求去消费特定分区的消息，consumer 指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer 拥有 了 offset 的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的.

#### 6.Kafka 消息是采用 Pull 模式，还是 Push 模式？ 

 Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消息推送到 consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统 的设计：producer 将消息推送到 broker，consumer 从 broker 拉取消息 

 一些消息系统比如 Scribe 和 Apache Flume 采用了 push 模式，将消息推送到下游的 consumer。这样做有好处也有坏处：由 broker 决定消息推送的速率，对于不同消费速率的 consumer 就不太好处理了。消息系统都致力于让 consumer 以最大的速率最快速的消费消 息，但不幸的是，push 模式下，当 broker 推送的速率远大于 consumer 消费的速率时， consumer 恐怕就要崩溃了。最终 Kafka 还是选取了传统的 pull 模式  

 Pull 模式的另外一个好处是 consumer 可以自主决定是否批量的从 broker 拉取数据。Push 模式必须在不知道下游 consumer 消费能力和消费策略的情况下决定是立即推送每条消息还 是缓存之后批量推送。如果为了避免 consumer 崩溃而采用较低的推送速率，将可能导致一 次只推送较少的消息而造成浪费。Pull 模式下，consumer 就可以根据自己的消费能力去决定这些策略 

 Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询， 直到新消息到 t 达。为了避免这点，Kafka 有个参数可以让 consumer 阻塞知道新消息到达 (当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发  

####  7.Kafka 存储在硬盘上的消息格式是什么？  

 消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和 CRC32 校验码。 

消息长度: 4 bytes (value: 1+4+n) 

版本号: 1 byte 

CRC 校验码: 4 bytes 

具体的消息: n bytes 

####  8.Kafka 高效文件存储设计特点：  

 (1).Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定 期清除或删除已经消费完文件，减少磁盘占用。 

(2).通过索引信息可以快速定位 message 和确定 response 的最大大小。 

(3).通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。

 (4).通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小。  

####  9.Kafka 与传统消息系统之间有三个关键区别 

(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留 

(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据 提升容错能力和高可用性 			    		(3).Kafka 支持实时的流式处理 

####  10.Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中 

副本因子不能大于 Broker 的个数； 

第一个分区（编号为 0）的第一个副本放置位置是随机从 brokerList 选择的； 

其他分区的第一个副本放置位置相对于第 0 个分区依次往后移。也就是如果我们有 5 个 Broker，5 个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五 个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推； 

剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是 随机产生的  

####  11.Kafka 新建的分区会在哪个目录下创建 

在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录， 这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘 上用于提高读写性能。 当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。 如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个 目录下创建文件夹用于存放数据。但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？ 答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic 名+分区 ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就 是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁 盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。

####    12.partition 的数据如何保存到硬盘

 topic 中的多个 partition 以文件夹的形式保存到 broker，每个分区序号从 0 递增， 且消息有序 Partition 文件下有多个 segment（xxx.index，xxx.log） segment 文件里的 大小和配置文件大小一致可以根据要求修改 默认为 1g 如果大小大于 1g 时，会滚动一个新的 segment 并且以上一个 segment 最后一条消息的偏移 量命名  

####  13.kafka 的 ack 机制 

request.required.acks 有三个值 0 1 -1 0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候 就会丢数据 1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader 挂掉后他 不确保是否复制完成新 leader 也会导致数据丢失 -1：同样在 1 的基础上 服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出 的 ack，这样数据不会丢失 

####  14.Kafka 的消费者如何消费数据 

消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置 等到下次消费时，他会接着上次位置继续消费 

####  15.消费者负载均衡策略 

一个消费者组中的一个分片对应一个消费者成员，他能保证每个消费者成员都能访问，如 果组中成员太多会有空闲的成员  

####  16.数据有序

 一个消费者组里它的内部是有序的 消费者组与消费者组之间是无序的  

####  17.kafaka 生产数据时数据的分组策略 

生产者决定数据产生到集群的哪个 partition 中 每一条消息都是以（key，value）格式 Key 是由生产者发送数据传入 所以生产者（key）决定了数据产生到集群的哪个 partition


## 为什么是用消息队列

- 解耦
- 异步
- 削峰

#### 解耦

 现有系统A，B，C，系统B和C需要系统A的数据，然后我们就修改系统A的代码，给系统B，C发送数据。这时系统D也需要系统A的数据，我们又要修改系统A的代码，给系统D发送数据。如果这时系统B不需要系统A的数据了呢? 简直崩溃了，新增或减少一个系统，我们都要去修改系统A的代码，而且我们还需要考虑调用的系统挂掉了怎么办，是否要将数据存起来，是否要重发等等，这是非常不合理的一种设计，我们需要引入消息队列。 

 引入消息队列后，系统A产生的数据直接发送到消息队列中，哪个系统需要系统A的数据就直接去消息队列中消费，这样系统A就和其他系统彻底解耦了。 

#### 异步

 客户端调用A系统的一个接口处理某个功能，该功能需要调用B，C，D系统进行处理，如果A系统自身耗时为20ms，B，C，D系统耗时分别是300ms，450ms，200ms，最终接口返回时总共耗时970ms，这肯定是不可接受的，我们需要引入消息队列。 

 引入消息队列后，系统A将消息发送到消息队列中就可以直接返回，接口总共耗时很短，用户体验非常棒。 

####  **削峰** 

 在高并发场景下(比如秒杀活动)某一刻的并发量会非常高，如果这些请求全部到达MySQL，会导致MySQL崩溃，这时我们需要引入消息队列，先将请求积压到消息队列中，让MySQL正常处理。 

## 消息队列有什么优缺点  

(1) 优点

- 解耦
- 异步
- 削峰

(2) 缺点

- 系统可用性降低，MQ一旦挂掉，整个系统就崩溃了。
- 系统复杂度提高，引入MQ后需要考虑一系列问题，比如消息丢失，重复消费，消息消费的顺序等等。
- 一致性问题，没有引入MQ之前有事务来保证一致性，引入MQ后如果某一步执行失败，这就导致数据不一致了。

## ActiveMQ、RabbitMQ、Kafka、RocketMQ 优点和缺点

(1) ActiveMQ和RabbitMQ单击吞吐量是万级，Kafka和RocketMQ的单机吞吐量是10万级。

(2) 四种MQ的时效性，可用性，消息可靠性都很高。

(3) ActiveMQ的社区不太活跃，其他三种MQ的社区比较活跃。

(4) RabbitMQ是基于Erlang语言开发，对Java开发者不太友好。

(5) Kafka当topic数量达到1000时吞吐量会大幅度下降，而RocketMQ影响不太(这是RocketMQ相对于Kafka的一大优势)。

(6) Kafka的功能简单，吞吐量高，天然适合大数据实时计算以及日志采集。

## 如何保证消息队列的高可用 

**回答自己熟悉的消息队列，如Kafka。**

Kafka是一个分布式的消息队列，一个topic有多个partition，每个partition分布在不同的节点上。此外，Kafka还可以为partition配置副本机制，一个主副本对外提供服务，多个从副本提供冷备功能(即只起备份作用，不提供读写)。

(1) 从副本为什么不提供读写服务，只做备份?

因为如果follower副本也提供写服务的话，那么就需要在所有的副本之间相互同步。n个副本就需要 n x n 条通路来同步数据，如果采用异步同步的话，数据的一致性和有序性是很难保证的，而采用同步方式进行数据同步的话，那么写入延迟其实是放大n倍的，反而适得其反。

(2) 从服务为什么不提供读服务呢?

这个除了因为同步延迟带来的数据不一致之外，不同于其他的存储服务（如ES，MySQL），Kafka的读取本质上是一个有序的消息消费，消费进度是依赖于一个叫做offset的偏移量，这个偏移量是要保存起来的。如果多个副本进行读负载均衡，那么这个偏移量就不好确定了。

总结一下，从副本不提供读写服务的原因就是很难保证数据的一致性与有序性，而且也没必要提供读写服务，Kafka是一个消息队列，副本的作用是保证消息不丢失。

**partition主从副本数据同步**

生产者发布消息到某个分区时，先通过ZooKeeper找到该分区的leader副本，然后将消息只发送给leader副本，leader副本收到消息后将其写入本地磁盘。接着每个follower副本都从leader副本上pull消息，follower副本收到消息后会向leader副本发送ACK(acknowledge)。一旦leader副本收到了 ISR (in-sync replicas) 中的所有副本的ACK，该消息就被认为已经commit了，然后leader副本向生产者发送ACK。消费者读消息只会从leader副本中读取，只有被commit过的消息才会暴露给消费者。

ISR(in-sync replicas)是与leader副本保持同步状态的follower副本列表，如果一段时间内(replica。lag。time。max。ms) leader副本没有收到follower副本的拉取请求，就会被leader副本从ISR中移除。ISR中的副本数必须大于等于 min。insync。replicas，否则producer会认为写入失败，进行消息重发。

**主副本选举**

当leader副本挂掉后，集群控制器(即Master节点)会从ISR中选出一个新的主副本(ISR中的第一个，不行就依次类推 )。

**集群控制器选举**

集群中的第一个broker通过在Zookeeper的 /controller 路径下创建一个临时节点来成为控制器，当其他broker启动时，也会试图创建一个临时节点，但是会收到“节点已存在”的异常，这样便知道集群控制器已存在。这些broker会监听Zookeeper的这个控制器临时节点，当控制器发生故障时，该临时节点会消失，这些broker便会收到通知，然后尝试去创建临时节点成为新的控制器。

**如何保证消息不被重复消费（如何保证消息消费时的幂等性）?**

(1) 导致消息重复消费的原因?分区重平衡消费者重启或宕机这两个原因都会导致消费者在消费消息后没有提交offset。

(2) 解决办法这个问题只能通过业务手段来解决，比如我们在消费前先查询数据库，判断是否已消费(status = 1)，或消费后在Redis中做个记录，下次消费前先从Redis中判断是否已消费。

**如果保证消息不丢失(如何保证消息的可靠性传输)?**

(1) 导致消息丢失的原因?

kafka没有保存消息。消费者还没消费就提交了offset，然后消费者重启或宕机，分区重平衡。
		(2) 解决办法

配置partition副本机制。

•default。replication。factor 每个分区的副本数必须大于1。

•min。insync。replicas 与主副本保存同步状态的从副本数必须大于等于1。

•Producer端的配置acks=all，指数据写入min。insync。replicas个从副本后才算写入成功。

•Producer端的配置retries=MAX(一个很大的值，表示无线重试的意思)，指数据一旦写入失败，就无限重试。关闭自动提交offset，改为手动提交。先消费，消费成功后再手动提交offset。

## 如何保证消息的顺序性？

kafka只保证单个分区内的消息有序，所以要想保证消息的顺序性，只能一个topic，一个partition，一个consumer。

如果在consumer端开多个线程来进行消费，如何保证消息的顺序性?

一个topic，一个partition，一个consumer，consumer内部单线程消费，写N个内存queue，然后开N个线程分别消费一个内存queue中的消息。

**消息队列快写满了怎么办?**

一般出现这种问题的原因就是消费端出了故障，导致无法消费或消费极慢，这时有两种解决办法，根据不同的场景选择不同的解决办法。

(1) 紧急扩容临时征用10倍的机器来部署consumer，新建一个topic，partition是原来的10倍。写一个临时分发数据的consumer程序，将积压的数据不做处理，直接分发给临时建好的topic。以10倍的速度消费积压的消息，消费完之后再恢复原来的部署。

(2) 批量重导写一个临时分发数据的consumer程序，将积压的数据直接丢弃。等高峰期过后，写个临时程序，将丢失的那批数据重新导入消息队列中。
如果让你自己写一个消息队列，该如何进行架构设计？

我们可以用Kafka的架构设计来回答这个问题。

(1) 分布式这个消息队列必须分布式的，这样通过水平扩展集群就可以增加消息队列的吞吐量与容量。分布式的消息队列必须要有一个master节点来管理整个集群，可以通过Zookeeper来实现master节点选举算法。

(2) 可用性一个topic必须支持多个partition，且partition数量可以增加，每个partition分布在不同的节点上。partition内通过offset来保证消息的顺序。同时为了保证可用性，每个分区必须设置副本，主副本提供读写服务，从副本只作备份即可。当主副本所在的节点宕机后，master节点会在从副本中选出一个作为主副本，然后当宕机的节点修复后，master节点会将缺失的副本分配过去，同步数据后，集群恢复正常。

(3) 高性能为了保证高吞吐量，我们可以使用批量压缩，顺序写，零拷贝技术。

(4) 解决消息丢失方案消息必须写入所有副本中才算写入成功。

## Kafka 为什么速度那么快？

我们都知道Kafka的核心特性之一就是高吞吐率，但Kafka的数据是存储在磁盘上的，一般认为在磁盘上读写数据性能很低，那Kafka是如何做到高吞吐率的呢?

- 批量压缩
- 顺序写
- 零拷贝 

Kafka高吞吐率的秘诀在于，它把所有的消息都进行批量压缩，提升网络IO，通过顺序写和零拷贝技术提升磁盘IO。
