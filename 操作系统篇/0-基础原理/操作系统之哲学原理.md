# 操作系统之哲学原理

## 基础原理篇

1.1 程序是如何运行的？

```
程序的运行至少需要如下四个因素：
1、程序设计语言
2、编译系统
3、操作系统
4、指令集结构（计算机硬件系统）
```

1.2 什么是操作系统

```
1、操作系统是一个软件系统
2、操作系统使计算机变得好用（将人类从繁琐、复杂的对机器掌控的任务中解脱）
3、操作系统是掌控计算机上所有事情的软件系统
```

1.3 操作系统的功能

```
1、替用户及其应用管理计算机上的软硬件资源
2、保证计算机资源的公平竞争和使用
3、防止对计算机资源的非法侵占和使用
4、保证操作系统自身正常运转
```

1.4 根据管理的资源不同，操作系统具体功能如下：

```
CPU管理：即如何分配CPU给不同应用和用户
内存管理：即如何分配内存给不同应用和用户
外存管理：即如何分配外存（磁盘）给不同应用和用户
I/O管理：即如何分配输入输出设备给应用和用户
健壮性管理：即如何确保操作系统自身的正常运作
安全性管理：即如何防止非法操作和入侵
```

```
CPU管理就是将要介绍的进程管理。进程管理的主要目的有3个：第一个是公平，即每个程序都有机会使用CPU。第二个是非阻塞（non-blocking），即任何程序不能无休止地阻挠其他程序的正常推进。如果一个程序在运行过程中需要输入输出或者因别的什么事情而发生阻塞，这个阻塞不能妨碍别的进程继续前进。就像人类世界，缺了谁地球照样旋转。第三个是优先级。在人类生活中人的地位不完全一样，地位高的就比地位低的优先级高。人类把自己生活中的这种关系搬到操作系统里面，就有了优先级的概念，即某些程序比另外一些程序优先级高。如果优先级高的程序开始运行，则优先级低的程序就要让出资源。就像我们经常说的，我们坚决反对大锅饭，应该让一部分人（程序）先富起来。
内存管理主要是管理缓存、主存、磁盘、磁带等存储介质所形成的内存架构。为此目的，操作系统设计人员发明了虚拟内存的概念，即将物理内存（缓存和主存）扩充到外部存储介质（磁盘、光盘和磁带）上。这样内存的空间就大大地增加了，能够运行的程序的大小也大大地增加了。内存管理的另一个目的是让很多程序共享同一个物理内存。这就需要对物理内存进行分割和保护，不让一个程序访问另一个程序所占的内存空间，专业术语称为运行时不能越界。在生活中，就是我家的东西不希望你跑来拿。
外存管理通常也称为存储管理，它就是众所周知的文件系统了。文件系统的主要目的是将磁盘变成一个很容易使用的存储媒介以提供给用户使用。这样我们在访问磁盘时无须了解磁盘的物理属性或数据在磁盘上的精确位置，诸如磁道、磁柱、扇面等。当然，文件系统还可以建立在光盘和磁带上。只是使用最为频繁的文件系统都以磁盘为介质。
I/O管理也称为设备管理，就是管理输入输出设备。I/O管理的目的有两个：一是屏蔽不同设备的差异性，即用户用同样的方式访问不同的设备，从而降低编程的难度；二是提供并发访问，即将那些看上去并不具备共享特性的设备（如打印机）变得可以共享。
另外还有一个任务称为批处理，它提供一种无需人机交互的程序运行模式。有时我们不需要人来交互，就交给计算机批处理。主要目的是达到吞吐量最大化，单位时间完成的任务最多。图1-8描述的是操作系统的5个核心功能。
```

1.5 内核态与用户态

```
内核态就是拥有资源多的状态，或者说访问资源多的状态，称为特权态。（CPU的管理和内存管理，诊断和测试程序，输入和输出，文件系统本身的管理）
相对来说，用户态就是非特权态，在此状态下访问的资源将受到限制，如果一个程序运行在特权态，则该程序就可以访问计算机的任何资源，即它的访问不受限制，如果一个程序运行在用户态，则其资源需求将受到各种限制。
用户态和内核态就是CPU的一种状态，有一个状态字可以设置，一个程序运行时，CPU是什么态，这个程序就是运行在什么态
```

1.6 进程、内存和文件

```
进程就是进展中的程序，一个程序一旦运行，它就是一个进程，操作系统对进程的管理是通过进程表来实现，进程表理存放的是关于进程的一切信息，在任何时候，进程所占有的全部资源，包括分配给进程的内存，内核数据结构和软资源形成一个进程核core。核快照core image代表的是进程在某一特定时刻的状态
如果在Linux或UNIX操作系统下编写程序，在出现分段错误（segmentation fault）时，操作系统会自动进行核倒出（core dump）。“核倒出”把所有计算机的状态保存在一个文件中，通过阅读这个文件的内容可以得知溢出时的进程状况，从而帮助调试程序。
内存是操作系统里面的另一个核心概念。它是进程的存放场所。如何对内存进行管理，使得数据的读写具有高效率、高安全、高空间利用率和位置透明的特性是内存管理所要达到的目的。
文件是操作系统提供的外部存储设备的抽象，它是程序和数据的最终存放地点。如何让用户的数据存放变得容易、方便、可靠和安全是文件系统要解决的问题。
```

1.7 系统调用

```
前面说过，操作系统是一个系统程序，即为别的程序提供服务的程序。那么操作系统的服务是通过什么方式提供的呢？答案是系统调用（system call）
系统调用按照功能可以划分为六大类：
	进程控制类。
	文件管理类。
	设备管理类。
	内存管理类。
	信息维护类。
	通信类。
系统调用分为三个阶段，分别是：
	参数准备阶段。
	系统调用识别阶段。
	系统调用执行阶段。
```

1.8 壳

```
为了向这些不编程的用户提供服务，操作系统提供了一个壳（shell）来与用户交互。每个操作系统都提供某种壳，以便与用户进行交互。这个壳是覆盖在操作系统服务上面的一个用户界面，既可以是图形界面，也可以是文本界面。用户在这个界面上输入命令，操作系统则执行这些命令。当然，用户输入的命令不是直接的操作系统服务，而是所谓的utilities。utilities的功用相当于C语言中的库函数。
一个壳的具体功能包括如下几项：
	显示提示符，如UNIX下的提示符通常为-和%。
	接受用户命令并执行。
	实现输入输出间接（或间接输入输出）。
	启动后台进程。
	进行工作控制。
	提供伪终端服务。

```

## 进程原理篇

1.什么是进程，进程出现的动机是什么?

```
进程就是进展中的程序，或者说进程是执行中的程序。就是说，一个程序加载到内存后就变为进程。即：进程=程序+执行
为了提高CPU利用率，人们想起将多个程序同时加载到计算机里，并发执行。这些同时存在于计算机内存的程序就称为进程。进程让每个用户感觉到自己独占CPU。因此，进程就是为了在CPU上实现多道编程而出现的概念
```

2.进程模型

```
那么进程到底是什么呢？什么是进展中的程序呢？从物理内存的分配来看，每个进程占用一片内存空间，从这点上说，进程就是内存的某片空间。由于在任意时刻，CPU只能执行一条指令，因此任意时刻在CPU上执行的进程只有一个，而到底执行哪条指令由物理程序计数器指定。也就是说，在物理层面上，所有进程共用一个程序计数器。

而从逻辑层面上来看，每个进程可以执行，也可以暂时挂起让别的进程执行，之后又可以接着执行。这样，进程就需要某种办法记住每次挂起时自己所处的执行位置，这样才能在下次接着执行时从正确的地点开始。因此，从这个角度看，每个进程有着自己的计数器，记录其下一条指令所在的位置。从逻辑上说，程序计数器可以有很多个。

而从时间上看，每个进程都必须往前推进。在运行一定的时间后，进程都应该完成了一定的工作量，即每次进程返回，它都处在上次返回点之后。这就像古希腊哲学家赫拉克里特说过的：“一个人不能两次踏入同一条河流。”
```

3.进程模型的实现

```
对于操作系统来说，进程是其提供的一种抽象，目的是通过并发来提高系统利用率，同时还能缩短系统响应时间。这种抽象听上去很不错。但这种抽象是如何实现的呢？或者说，操作系统如何实现进程呢？首先，任何抽象都需要有一个物理基础。对于进程来说，其物理基础就是程序。程序运行在计算机上，而在计算机上运行首先需要解决的问题是进程的存储：给进程分配合适的内存，让其有一个安身之处。由于多个进程可能同时并存，因此进程的存储需要考虑如何让多个进程共享同一个物理内存而不发生冲突。操作系统解决这个问题的手段是内存管理。此外，进程运行实际上是指进程在CPU上执行。那么如何将CPU在多个进程之间进行交接或切换，这就是进程实现需要解决的另一个问题。操作系统解决这个问题的手段就是进程调度：决定在什么时候让什么进程使用CPU。
```

4.进程的产生与消亡

```
什么事件可以造成进程的产生和消亡呢？当然有很多这样的事件。对于进程产生来说，主要的事件有：
●系统初始化（神创造人）。
●执行进程创立程序（人生子）。
●用户请求创立新进程（试管婴儿）。

造成进程消亡的事件则可以分为四种情况：
●寿终：进程运行完成而退出。
●自杀：进程因错误而自行退出。
●他杀：进程被其他进程所终止。
●处决：进程因异常而被强行终结。
```

5.进程的层次结构

```
一个进程在执行过程中可以通过系统调用创建新的进程。这个新创建的进程就称为子进程，而创建子进程的进程则称为父进程。子进程又可以再创建子进程，这样子子孙孙创建下去就形成了所谓的进程树。UNIX称这个进程树里面的所有进程为一个进程组，进程组里面的进程分布在不同的层次上，从而形成一个层次架构。
Windows没有进程组的概念，而是所有进程均地位平等
```

6、进程的状态

```
我们前面说过，进程可以在CPU上执行，也可以处于挂起状态。显然，一个进程至少有这么两种状态。那么进程还有别的状态吗？如果进程在CPU上执行，自然就是执行状态。而如果是挂起状态呢？那就得看是什么原因挂起的。因为操作系统在进行进程调度时要从挂起的进程中选择一个来执行，所以清楚一个进程挂起的原因对调度的有效推进十分重要。那么进程挂起有哪些原因呢？首先是一个进程在运行过程中执行了某种阻塞操作，如读写磁盘。由于阻塞操作需要等待结果后才能继续执行，因此操作系统将把这个进程挂起，让其他进程运转。另外一种情况是一个进程执行的时间太长了，为了公平，操作系统将其挂起，让其他进程也有机会执行。这两种挂起的原因十分不同：第一种挂起是进程自身的原因。这个时候，即使把CPU控制权交给它，它也无法运行。第二种挂起是操作系统的原因。进程自己并无问题。只要把CPU交给进程，它就可以立即运行。这样，如果将挂起进程分为这样两类，操作系统在进程调度时就只需要查看第二类进程，而无须浪费时间查看第一类进程。
因此，将进程分为3种状态：执行、阻塞和就绪
```

7、进程与地址空间

```
进程空间也称为地址空间。简单来说，地址空间就是进程要用的所有资源。于是所有资源就构成了状态的划分。由于不可能有两个进程状态完全一样，因此每个进程对应计算机的一种状态，而计算机状态就是所有存储单元的内容。地址空间的特点就是被动，自己不能做什么，只提供支持。打个比方。看过演出吗？如话剧、芭蕾、歌剧等。京剧总看过吧？有个舞台，那些道具和舞台就是地址空间。这些空间本身不能发生任何动作。做动作的只能是演员。而那些演员就是我们将要讲述的线程。跳上来一个演员就是一个线程
```

8、进程管理

```
那么谁管理进程的资源？是操作系统，作系统要掌控一切状态，就必须拥有某些手段或资源。那需要什么手段或资源呢？如果让你监视一群人，要你掌握他们的一切情况，你第一件要做的事是什么？装监视器？不是！而是要知道这群人到底是哪些人！即你需要知道并维持关于这群人的各种信息！
```

9、进程管理所需要的手段

```
与一个社会管理人的过程类似，操作系统要管理进程就要维护关于进程的一些信息。当一个进程产生时，操作系统也需要为其创建记录。操作系统用于维护进程记录的结构就是进程表或进程控制块（Process ControlBlock, PCB）。这个进程表或PCB中存放的就是有关该进程的资料。那么进程表里有什么资料呢？显然，不同的操作系统维护的进程资料不尽相同。但一般来说，维护的资料信息应当包括寄存器、程序计数器、状态字、栈指针、优先级、进程ID、信号、创建时间、所耗CPU时间、当前持有的各种句柄等。而采纳的数据结构主要是线性表、链表和结构（struct），当然也可能使用树和图（网络）结构。
```

10、进程的创建过程

```
前面说过，对于一个计算机系统来说，不断创建和终结进程，创建进程和终结进程各有4种方法。但操作系统是如何创建一个进程的呢？一般来说，创建进程的步骤如下所示：
1）分配进程控制块。
2）初始化机器寄存器。
3）初始化页表。
4）将程序代码从磁盘读进内存。
5）将处理器状态设置为“用户态”。
6）跳转到程序的起始地址（设置程序计数器）。
这里一个最大的问题是，跳转指令是内核态指令，而在第5步时处理器状态已经被设置为用户态，但在用户态下是不能执行内核态指令的。这个问题如何解决？当然了，这就需要硬件帮忙了。硬件必须将第5和第6两步作为一个步骤一起完成。
```

11、进程管理要处理的问题

```
进程管理的最大问题是资源分配。那么如何分配资源呢？人类社会最大的问题也是资源分配。谁能解决资源争端，让地球上每个人高高兴兴地共享资源，谁就是人类的救星。当然，计算机的资源分配问题不像人类那样困难，因为程序没有自我意识，就算我们对某些程序不公平，它们也无法抱怨。但这不能成为我们偷懒和堕落的理由。毕竟，我们制造计算机就是想好好地利用它，自然希望能够让所有进程高兴地相处在一起。毕竟，我们的本性还是追求公平的。除了公平之外，还有一个问题要考虑：效率，也就是最优。每个进程分配同样的资源肯定不行。以前32个终端连到一台计算机上，慢得不行，结果没有任何人高兴。不如让部分人先富起来，给他们使用资源的优先权。这样，公平与效率就成了进程管理中永恒的主题。到底是公平重要，还是效率重要？天平的不同倾斜将引出十分不同的进程管理模式。
```

12、进程缺陷

```
如果仔细观察，就会发现，进程有个很严重的问题。假定现在有两部很好的电影，都只放映一次，以后再也不放映了。而且，这两部电影同时放映，当然了，是在不同的两个房间放映。而你很想将这两部电影都看了，有什么办法吗？假定没有光碟刻录机也没有录像机等。当然，我们没有办法同时看两部电影。这也是进程的缺点。它只能在一个时间做一件事情。如果想同时做两件或多件事情，进程就不够用了。另外，更为重要的是，如果进程在执行的过程中阻塞，例如等待输入，整个进程就将挂起（暂停），而无法继续执行。这样，即使进程里面有部分工作不依赖于输入数据，也无法推进。
```

13、进程调度

```
那么操作系统进程调度的目标是什么呢？这需要对进程使用CPU的模式进行分析。那么进程在执行时有什么样的模式呢？
一般来说，程序使用CPU的模式有3种：一种是程序大部分时间在CPU上执行；另一种是程序大部分时间在进行输入输出；还有一种是程序介于前两种模式之间。
第1种程序运行的模式是在CPU上执行较长时间，接着进行短暂的输入，然后又在CPU上进行较长的运算，之后又进行短暂的输入输出操作，就这样循环往复。这种程序由于使用CPU的时间远远长于其用于输入输出上的时间，因此称为CPU导向（CPU-bound）或计算密集型程序。计算密集型程序通常是科学计算方面的程序。计算宇宙大爆炸各种参数的程序、矩阵乘法程序等就都是CPU导向的程序。
第2种程序则与第1种相反，这种程序的大部分时间用来I/O，每次I/O后进行短暂的CPU执行，因此称为I/O导向（I/O-bound）或输入输出密集型程序。一般来说，人机交互式程序均属于这类程序。如游戏程序以及讲课时使用的PPT程序，都属于I/O导向的程序。
第3种程序自然介乎二者之间，既有长时间的CPU执行部分，又有长时间的I/O部分。或者说，这种程序使用CPU和I/O的时间相差不大。这种程序称为平衡型程序。例如，网络浏览或下载、网络视频等就属于此类程序。
```

14.进程调度的目标

```
CPU调度就是要达到极小化平均响应时间、极大化系统吞吐率、保持系统各个功能部件均处于繁忙状态和提供某种貌似公平的机制。
```

### 进程调度算法

15、先来先服务调度算法

```
先来先服务调度算法缩写为FCFS（First Come First Serve）。谁先来，就先服务谁。这个算法所有地球人都能想到。因为先来先到是人的本性中的一种公平观念，而且生活实际中这种规则随处可见。例如，我们排队买东西或者办理政务体现的就是先来先到原则。先来先到的一个隐含条件就是不能抢占，一个程序一旦启动就一直运行到结束或者受阻塞为止。这是因为一旦允许抢占，就破坏了先来先到的原则。先来先到的优点就是简单，人人都能理解，实现起来容易。而缺点则是短的工作有可能变得很慢，因为其前面有很长的工作。这样就造成用户的交互式体验也比较差
```

16、时间片轮转算法

```
时间片轮转算法是对FCFS算法的一种改进，其主要目的是改善短程序的响应时间。其方法就是周期性地进行进程切换
```

17、短任务优先算法

```
那要改善短任务排在长任务后面轮转而造成响应时间和交互体验下降的办法就是短任务优先（Shorted Timeto Completion First, STCF）算法。这种算法的核心是所有的程序并不都一样，而是有优先级的区分。具体来说，就是短任务的优先级比长任务的高，而我们总是安排优先级高的程序先运行。就像晚辈在公交汽车上见到长辈需要让座一样。
短任务优先算法有两个变种：一种是非抢占，一种是抢占。非抢占短任务优先算法的原理是让已经在CPU上运行的程序执行到结束或阻塞，然后在所有候选的程序中选择需要执行时间最短的进程来执行。抢占式短任务优先算法则是每增加一个新的进程就需要对所有进程（包括正在CPU上运行的进程）进行检查，谁的时间短，就运行谁。

```

18.优先级调度算法

```
前面介绍的STCF算法有一个缺点是可能造成长进程“饥饿”。但这个问题比较容易解决，使用优先级即可。优先级调度算法的原理是给每个进程赋予一个优先级，每次需要进程切换时，找一个优先级最高的进程进行调度。这样，如果赋予长进程一个高优先级，则该进程就不会再“饥饿”。事实上，STCF算法本身就是一种优先级调度，只不过它给予短进程高优先级而已。
优先级调度的优点是可以赋予重要的进程以高优先级以确保重要任务能够得到CPU时间。其缺点则与STCF算法一样，低优先级的进程可能会“饥饿”。不过，这个问题在优先级调度算法里比在STCF里好解决：只要动态地调节优先级即可。例如，在一个进程执行特定CPU时间后将其优先级降低一个级别，或者将处于等待进程的优先级提高一个级别。这样，一个进程如果等待时间很长，其优先级将因持续提升而超越其他进程的优先级，从而得到CPU时间。这样，“饥饿”现象就可以防止。
```

19、混合调度算法

```
混合调度算法。该算法的原理是将所有进程分成不同的大类，每个大类为一个优先级。如果两个进程处于不同的大类，则处于高优先级大类的进程优先执行；如果两个进程处于同一个大类，则采用时间片轮转来执行。混合调度算法的示意图如图5-3所示。
```

20、进程调度的过程（重点）

```
首先，当然需要将当前进程的状态予以保护，以便将来能够重新执行。然后是将选中的进程的环境布置好，这包括设置寄存器、栈指针、状态字等操作。最后是跳转到选中的进程，也就是设置或恢复其程序计数器。下面给出的是调度进程时操作系统所执行的操作概览：
●因时序或外部中断或进程挂起而导致操作系统获得CPU控制权。
●操作系统在所有就绪的进程中按照某种算法遴选进程。
●如果选中的是非当前进程，则操作系统将当前进程（中断或挂起的进程）状态予以保护。
●将选中的进程的环境布置好（设置寄存器、栈指针、状态字等）。
●跳转到选中的进程。
```

21、管道

```
从根本上说，管道是一个线性字节数组，类似文件，可以使用文件读写的方式进行访问。但却不是文件。因为通过文件系统看不到管道的存在。另外，我们前面说了，管道可以设在内存里，而文件很少设在内存里
在程序里面，创建管道需要使用系统调用popen（）或者pipe（）。popen（）需要提供一个目标进程作为参数，然后在调用该函数的进程和给出的目标进程之间创建一个管道。这很像人们打电话时必须提供对方的号码，才能创建连接一样。
创建时还需要提供一个参数表明管道类型：读管道或者写管道。而pipe（）调用将返回两个文件描述符（文件描述符是用来识别一个文件流的一个整数，与句柄不同），其中一个用于从管道进行读操作，一个用于写入管道。也就是说，pipe（）将两个文件描述符连接起来，使得一端可以读，另一端可以写。通常情况下，使用pipe（）调用创建管道后，再使用fork产生两个进程，这两个进程使用pipe（）返回的两个文件描述符进行通信。
```

22、记名管道

```
如果要在两个不相关的进程（如两个不同进程里面的进程）之间进行管道通信，则需要使用记名管道。顾名思义，命名管道是一个有名字的通信管道。记名管道与文件系统共享一个名字空间，即我们可以从文件系统中看到记名管道。也就是说，记名管道的名字不能与文件系统里的任何文件名重名
```

23、套接字

```
套接字（socket）是另外一种可以用于进程间通信的机制。套接字首先在BSD操作系统中出现，随后几乎渗透到所有主流操作系统中。套接字的功能非常强大，可以支持不同层面、不同应用、跨网络的通信。使用套接字进行通信需要双方均创建一个套接字，其中一方作为服务器方，另外一方作为客户方。服务器方必须先创建一个服务区套接字，然后在该套接字上进行监听，等待远方的连接请求。欲与服务器通信的客户则创建一个客户套接字，然后向服务区套接字发送连接请求。服务器套接字在收到连接请求后，将在服务器方机器上创建一个客户套接字，与远方的客户机上的客户套接字形成点到点的通信通道。之后，客户方和服务器方就可以通过send和recv命令在这个创建的套接字通道上进行交流了。服务区套接字有点类似于传说中的虫洞（worm hole），如图6-3所示。虫洞的一端是开放的，它在宇宙内或宇宙间飘移着，另外一端处于一个不同的宇宙，监听是否有任何东西从虫洞来。而欲使用虫洞者需要找到虫洞的开口端（发送连接请求），然后穿越虫洞即可。
```

24、信号

```
●想迫使一方对我们的通信立即做出回应。
●我们不想事先建立任何连接，而是临时突然觉得需要与某个进程通信。
●传输的信息量微小，使用管道或套接字不划算。
应付上述需求，我们使用的是信号（signal）
那么信号是什么呢？在计算机里，信号就是一个内核对象，或者说是一个内核数据结构。发送方将该数据结构的内容填好，并指明该信号的目标进程后，发出特定的软件中断。操作系统接收到特定的中断请求后，知道是有进程要发送信号，于是到特定的内核数据结构里查找信号接收方，并进行通知。接到通知的进程则对信号进行相应处理。
信号非常类似我们生活当中的电报，如图6-8所示。如果你想给某人发一封电报，就拟好电文，将报文和收报人的信息都交给电报公司。电报公司则将电报发送到收报人所在地的邮局（中断），并通知收报人来取电报。发报时无需收报人事先知道，更无需进行任何协调。如果对方选择不对信号做出响应，则将被操作系统终止运行。
```

25、信号量

```
信号量（semaphore）是由荷兰人E.W.Dijkstra在20世纪60年代所构思出的一种程序设计构造。其原型来源于铁路的运行：在一条单轨铁路上，任何时候只能有一列列车行驶在上面（如图6-9）。而管理这条铁路的系统就是信号量。任何一列火车必须等到表明铁路可以行驶的信号后才能进入轨道。当一列列车进入单轨运行后，需要将信号改为禁止进入，从而防止别的火车同时进入轨道。而当列车驶出单轨后，则需要将信号变回允许进入状态。这很像以前的旗语
```

26、进程拥抱：共享内存

```
进程的拥抱就是共享内存（见图6-11）。共享内存就是两个进程共同拥有同一片内存。对于这片内存中的任何内容，二者均可以访问。要使用共享内存进行通信，一个进程首先需要创建一片内存空间专门作为通信用，而其他进程则将该片内存映射到自己的（虚拟）地址空间。这样，读写自己地址空间中对应共享内存的区域时，就是在和其他进程进行通信。
这里需要注意的是，使用全局变量在同一个进程的进程间实现通信不称为共享内存。
```

27、信件发送：消息队列

```
消息队列是一列具有头和尾的消息排列。新来的消息放在队列尾部，而读取消息则从队列头部开始
它无需固定的读写进程，任何进程都可以读写（当然是有权限的进程）。其次，它可以同时支持多个进程，多个进程可以读写消息队列。即所谓的多对多，而不是管道的点对点。另外，消息队列只在内存中实现。最后，它并不是只在UNIX和类UNIX操作系统中实现。几乎所有主流操作系统都支持消息队列。
```

## 线程原理篇

1、什么是线程？

```
那么线程是什么？我们知道，进程是运转的程序，是为了在CPU上实现多道编程而发明的一个概念。但是进程在一个时间只能干一件事情。如果想同时干两件事，例如同时看两场电影，我们自然想到传说中的分身术，就像孙悟空那样同时变出多个真身。
既然线程是进程的分身，那么每个线程自然在本质上是一样的，即拥有同样的程序文本。但由于是分身，自然也应该有不一样的地方，这就是线程执行时的上下文不一致。事实上，我们说线程是进程里面的一个执行上下文或者执行序列。显然，一个进程可以同时拥有多个执行序列。这就像舞台，舞台上可以有多个演员同时出场，而这些演员和舞台就构成了一出戏。类比进程和线程，每个演员是一个线程，舞台是地址空间，这个同一个地址空间里面的所有线程就构成了进程。
将进程分解为线程还可以有效地利用多处理器和多核计算机。在没有线程的情况下，增加一个处理器并不能提高一个进程的执行速度。但如果分解为多个线程，则可以让不同的线程同时运转在不同的处理器上，从而提高了进程的执行速度。
```

2、线程模型的实现

```
与进程一样，线程本身也对应某种物理现实，也需要存储和调度。在存储上，由于线程依附于进程而存在，其存储解决方案无需额外设计，而是直接附于进程存储方案上。
线程的调度却与进程调度有稍许不同。由于线程是在进程的基础上产生的概念（进程里面的一个执行序列），其调度可以由进程负责。当然，我们也可以将线程的调度交给操作系统。而这两种不同的调度推手就形成了线程的两种实现：用户态实现和内核态实现。由进程自己管理就是用户态线程的实现，由操作系统管理就是内核态线程实现。用户态和内核态的判断以线程表所处的位置为依据：位于内核叫内核态实现，位于用户层叫用户态实现。
```

3、内核态线程实现

```
那么操作系统怎么管理线程呢？与管理进程一样，操作系统要管理线程，就要保持维护线程的各种资料，即将线程控制块存放在操作系统内核空间。这样，操作系统内核就同时保有进程控制块和线程控制块。而根据进程控制块和线程控制块提供的信息，操作系统就可以对线程进行各种类似进程的管理，如线程调度、线程的资源分配、各种安全措施的实现等。
由操作系统来管理线程有很多好处，最重要的好处是用户编程简单。因为线程的复杂性由操作系统承担，用户程序员在编程时无需管理线程的调度，即无需担心线程什么时候会执行、什么时候会挂起。另外一个重要好处是，如果一个线程执行阻塞操作，操作系统可以从容地调度另外一个线程执行。因为操作系统能够监控所有的线程。
那么内核态线程实现有什么缺点呢？首先是效率较低。因为线程在内核态实现，每次线程切换都需要陷入到内核，由操作系统来进行调度。而从用户态陷入到内核态是要花时间的。另外，内核态实现占用内核稀缺的内存资源，因为操作系统需要维护线程表。操作系统所占内存空间一旦装载结束后就已经固定，无法动态改变。由于线程的数量通常大大多于进程的数量，因此随着线程数量的增加，操作系统内核空间将迅速耗尽。
```

4、用户态线程实现

```
那么用户态实现意味着什么呢？或者说用户态实现是什么意思呢？就是用户自己做线程的切换，自己管理线程的信息，而操作系统无须知道线程的存在。
那么在用户态如何进行线程调度呢？那就是用户自己写一个执行系统（runtime system）作调度器，即除了正常执行任务的线程外，还有一个专门负责线程调度的线程。由于大家都在用户态下运行，谁也不比谁占优势，要想取得CPU控制权只能靠大家的自愿合作。一个线程在执行完一段时间后主动把资源释放给别人使用，而在内核态下则无须如此。因为操作系统可通过周期性的时钟中断把控制权夺过来。在用户态实现情况下，执行系统的调度器（runtime scheduler）也是线程，没有能力强行夺走控制权，所以必须合作
```

5、现代操作系统的线程实现模型

```
用户态的执行系统负责进程内部线程在非阻塞时的切换；内核态的操作系统负责阻塞线程的切换。即我们同时实现内核态和用户态线程管理。其中内核态线程数量较少，而用户态线程数量较多。每个内核态线程可以服务一个或多个用户态线程。换句话说，用户态线程被多路复用到内核态线程上。例如，某个进程有5个线程，我们可以将5个线程分成两组，一组3个线程，另一组2个线程。每一组线程使用一个内核线程。这样，该进程将使用两个内核线程。如果一个线程阻塞，则与其同属于一组的线程皆阻塞，但另外一组线程却可以继续执行
```

6、从用户态进入内核态

```
首先，如果在程序运行过程中发生中断或异常，系统将自动切换到内核态来运行中断或异常处理机制
此外，程序进行系统调用也将造成从用户态进入到内核态的转换
```

## 内存管理篇

1、内存管理的引入

```
本篇最为重要的核心思想是虚拟内存。通过这种机制，操作系统为程序员或用户提供了4种抽象：
●程序的地址独立性
●地址空间的保护
●内存空量的巨量或无限扩大
●内存访问速度的大幅度提升
操作系统为实现虚拟内存而使用的“原料”却很简单：一点点缓存，一些主存和便宜的磁盘；其采用的机制也简单至极：动态地址翻译！
```

2、内存管理的环境

```
程序要运行，必须先加载到内存。但在很久以前，准确地说是在操作系统出现以前，程序并不需要加载到内存就能运行。实际上，在那个已经久远的年代里，程序曾经存放在卡片上，计算机每读一张卡片，就运行一条指令。因此，程序是直接从卡片到执行。但这种从外部存储媒介上直接执行指令的做法效率极低，且灵活性很差。因此，人们发明了内存储器来将需要运行的程序先行加载，再自动执行，从而提高效率和灵活性。这也导致了“存储的程序”概念的出现，而存储的程序概念又导致计算机及软件系统的革命性变化。此后，人们对内存的要求越来越多，越来越高。
内存管理机制负责对内存架构进行管理，使程序在内存架构的任何一个层次上的存放对于用户来说都是一样的。用户无须担心自己的程序是存储在缓存、主存、磁盘还是磁带上，反正运行、计算、输出的结果都一样。而内存管理实现这种媒介透明的手段就是虚拟内存。用我们多次讲过的“抽象”来说，虚拟内存就是操作系统提供给用户的另一“幻象”。这个幻象构建在内存架构的顶端，给用户提供一个比物理主存空间大许多的地址空间。
```

3、内存管理的目标

```
地址保护：一个程序不能访问另一个程序地址空间。
地址独立：程序发出的地址应与物理主存地址无关。
```

4、虚拟内存的概念

```
虚拟内存的概念听上去似乎有点太虚拟，但其实质则并不难理解。我们知道，一个程序如果要运行，必须加载到物理主存中。但是，物理主存的容量非常有限。因此，如果要把一个程序全部加载到物理主存，则我们所能编写的程序将是很小的程序。它的最大容量受制于主存容量（还要减去操作系统所占的空间和一些临时缓存空间）。另外，即使我们编写的每个程序的尺寸都小于物理主存容量，但还是存在一个问题：主存能够存放的程序数量将是很有限的，而这将极大地限制多道编程的发展。
虚拟内存的中心思想是将物理主存扩大到便宜、大容量的磁盘上，即将磁盘空间看做主存空间的一部分。用户程序存放在磁盘上就相当于存放在主存内。用户程序既可以完全存放在主存，也可以完全存放在磁盘上，当然也可以部分存放在主存、部分存放在磁盘。而在程序执行时，程序发出的地址到底是在主存还是在磁盘则由操作系统的内存管理模块负责判断，并到相应的地方进行读写操作。事实上，我们可以更进一步，将缓存和磁带也包括进来，构成一个效率、价格、容量错落有致的存储架构。即虚拟内存要提供的就是一个空间像磁盘那样大、速度像缓存那样高的主存储系统
```

5、操作系统在内存中的位置

```
操作系统占用RAM的底层，用户程序占用RAM的上层。
●操作系统占用RAM的底层和位于用户程序地址空间上面的ROM，用户程序位于中间。
第2种模式又分为3种情况：
●没有使用内存映射的输入输出，ROM里面全部是操作系统。
●使用了内存映射的输入输出，ROM的一部分是操作系统，另一部分属于I/O设备。
●使用了内存映射的输入输出，ROM全部属于I/O设备。
```

6、RAM和ROM？

```
随机存储器RAM(Random Access Memory)也叫主存，是与CPU直接交换数据的内部存储器。它可以随时读写（刷新时除外），而且速度很快，通常作为操作系统或其他正在运行中的程序的临时数据存储介质。RAM工作时可以随时从任何一个指定的地址写入（存入）或读出（取出）信息。它与ROM的最大区别是数据的易失性，即一旦断电所存储的数据将随之丢失。RAM在计算机和数字系统中用来暂时存储程序、数据和中间结果。
只读存储器（Read-Only Memory，ROM）以非破坏性读出方式工作，只能读出无法写入信息。信息一旦写入后就固定下来，即使切断电源，信息也不会丢失，所以又称为固定存储器。ROM所存数据通常是装入整机前写入的，整机工作过程中只能读出，不像随机存储器能快速方便地改写存储内容。ROM所存数据稳定 ，断电后所存数据也不会改变，并且结构较简单，使用方便，因而常用于存储各种固定程序和数据。 [1]
```

7、单道编程的内存管理

```
在单道编程环境下，整个内存里面只有两个程序：一个是用户程序，另一个是操作系统。
　　由于只有一个用户程序，而操作系统所占用的内存空间是恒定的，所以我们可以将用户程序总是加载到同一个内存地址上，即用户程序永远从同一个地方开始执行。
　　这样，用户程序里面的地址都可以事先计算出来，即在程序运行之前就计算出所有的物理地址。这种在运行前即将物理地址计算好的方式叫做静态地址翻译。下面看看此方式如何达到两个目标。
　　（1）地址独立：用户在编写程序时无需考虑具体的物理内存，用户程序始终都被加载到同一个物理地址上。
　　（2）地址保护：整个系统里面只有一个用户程序，因此，固定地址的内存管理因为只运行一个用户程序而达到地址保护。
```

8、多道程序的内存管理

```
在多道编程环境下，无法将程序总是加到固定的内存地址上，也就是无法使用静态地址翻译。因此，必须在程序加载完毕之后才能计算物理地址，也就是在程序运行时进行地址翻译，这种翻译称为动态地址翻译。
策略有两种：
	1）固定分区
　　顾名思义，固定分区管理就是讲内存分为固定的几个区域，每个区域大小固定。最下面的分区为OS占用，其他分区由用户程序使用。分区大小通常各不相同，当需要加载程序时，选择一个当前闲置且容量足够大的分区进行加载，如下图所示，这是一种共享队列的固定分区（多个用户程序排在一个共同的队列里面等待分区）
　　由于程序大小和分区大小不一定匹配，有可能形成一个小程序占用一个大分区的情况，从而造成内存里虽然有小分区闲置但无法加载大程序的情况。这时，我们就想到也许可以采用多个队列，给每个分区一个队列，程序按照大小排在相应的队列里，如下图所示，这时一种分开队列的固定分区
　　2）非固定分区
　　非固定分区的思想在于除了划分给OS的空间之外，其余的内存空间是作为一个整体存在的。当一个程序需要占用内存空间时，就在该片空间里面分出一个大小刚刚满足程序所需的空间。再来一个程序时，则在剩下的空间里再这样分出一块来。在这种模式下，一个程序可以加载到任何地方，也可以和物理内存一样大。
　　例如，一开始内存中只有OS，这时候进程A来了，于是分出一片与进程A大小一样的内存空间；随后，进程B来了，于是在进程A之上分出一片给进程B；然后进程C来了，就在进程B上面再分出一片给C。如此，进程A、B和C的起始地址都不是固定的
　　仔细一看，这种方式存在一个重大问题：每个程序像叠罗汉一样累计，如果程序B在成型过程中需要更多空间怎么办？（例如在实际程序中，很多递归嵌套函数调用的时候回造成栈空间的增长）因此，我们可以想到可以再一开始的时候给程序分配空间时就分配足够大的空间，留有一片闲置空间供程序增长使用
　　不过，OS怎么知道应该分配多少空间给一个程序呢？分配多了，就是浪费；而分配少了，则可能造成程序无法继续执行。
　　因此，可以在空间不够时，给程序换一个空间，这种方式将程序倒到磁盘上，再加载到内存中，被称为交换（swap）。但是，如果在交换模式下程序的增长超过了物理内存，就不能再交换了。此时，可以将程序按照功能分成一段一段功能相对完整的单元，一个单元执行完成后再执行下一个单元，这就是重叠（overlay）。
　　但是，交换内存管理这种方式存在两个重要问题：
　　（1）空间浪费：随着程序在内存与磁盘间的交换，内存将变得越来越碎片化，即内存将被不同程序分割成尺寸大小无法使用的小片空间。
　　（2）程序大小受限：这有两层意思，一是指空间增长效率低下（由于磁盘操作耗时，交换出去再找一片更大的空间来增长程序空间的做法效率非常低），二是空间增长存在天花板限制（单一程序不能超过物理内存空间）。
```

9、 闲置空间管理

```
在管理内存的时候，OS需要知道内存空间有多少空闲？这就必须跟踪内存的使用，跟踪的办法有两种：
　　（1）给每个分配单元赋予一个字位，用来记录该分配单元是否闲置。例如，字位取值为0表示单元闲置，取值为1则表示已被占用，这种表示方法就是位图表示法
　　（2）将分配单元按照是否闲置链接起来，这种方法称为链表表示法
　　 在链表表示下，寻找一个给定大小的闲置空间意味着找到一个类型为H的链表项，其大小大于或等于给定的目标值。不过，扫描链表速度通常较慢
```

![image-20201213103625847](C:/Users/未来我来/AppData/Roaming/Typora/typora-user-images/image-20201213103625847.png)

![image-20201213103637412](C:/Users/未来我来/AppData/Roaming/Typora/typora-user-images/image-20201213103637412.png)

### 页式内存管理

10、基址极限管理模式的问题

```
到目前为止，本书已经介绍了几种基本的内存管理方法，分别是固定加载地址的内存管理、固定分区的内存管理、非固定分区的内存管理和交换内存管理。固定加载地址的内存管理只适合于单道编程，而其他3种则可用于多道编程。这3种适用于多道编程的内存管理模式均使用同一种实现机制：基址与极限。基址与极限的工作原理是将程序发出的虚拟地址加在基址而获得物理地址。如果地址超过指定的极限，则视为地址出界而禁止访问，否则访问正常进行。在我们介绍过的3种多道编程的内存管理模式里，以交换内存管理最为灵活和先进。它可以解决因程序所需空间增长而无法继续运行的困难，又可以实现动态多道编程，可谓是多道编程内存管理“三剑客”里面的第一高手。但这个第一高手也不是什么问题都没有的。事实上，这种策略存在很多重大问题，而其中最重要的两
个问题是空间浪费和程序大小受限。
```

11、空间浪费问题

```
随着程序在内存与磁盘间的交换，内存将变得越来越碎片化，即内存将被不同程序分割成尺寸大小无法使用
的小片空间。例如，假定我们运行8个程序：A、B、C、D、E、F、G、H，其启动、内存需要和交换过程如
下：
★A启动，需占用内存200KB，分配空间1000KB～1199KB。
★B启动，需占用内存100KB，分配空间1200KB～1299KB。
★C启动，需占用内存300KB，分配空间1300KB～1599KB。
★A结束，释放内存空间1000KB～1199KB。
★D启动，需占用内存50KB，分配空间1000KB～1049KB。
★E启动，需占用内存100KB，分配空间1600KB～1699KB。
★C结束，释放内存空间1300KB～1599KB。
★F启动，需占用内存200KB，分配空间1300KB～1499KB。
★G启动，需占用内存50KB，分配空间1500KB～1549KB。
★H启动，需占用内存200KB，无法分配空间！
在上述前7个进程执行序列后，当前内存中尚有200KB的闲置空间，分别处于地址1050KB～1199KB和1550KB～1599KB。但因为不连续，所以无法容纳进程H。而进程H的空间需求只有200KB！
这种散布在进程之间的闲置空间称为外部碎片。这是因为从进程的粒度来看，这种碎片处于进程空间的外面。这种碎片化过程也称为“外部碎片化”
```

12、程序受限问题

```
除了外部碎片外，交换的内存管理模式还存在几个重大问题：地址空间增长困难。这有两层意思：一是指空间增长效率低下；二是空间增长存在天花板限制。
```

13、分页内存管理

```
为了解决交换系统存在的缺陷，出现了分页系统。分页系统的核心就是将虚拟内存空间和物理内存空间皆划分为大小相同的页面，如4KB、8KB或16KB等，并以页面作为内存空间的最小分配单位，一个程序的一个页面可以存放在任意一个物理页面里。这样，由于物理空间是页面的整数倍，并且空间分配以页面为单位，将不会再产生外部碎片。同时，由于一个虚拟页面可以存放在任何一个物理页面里，空间增长也容易解决：只需要分配额外的虚拟页面，并找到一个闲置的物理页面存放即可。
为了解决程序比内存大的问题，我们可以允许一个进程的部分虚拟页面存放在物理页面之外，也就是磁盘上。在需要访问这些外部虚拟页面时，再将其调入物理内存。由此，交换系统的所有缺陷均被克服。
```

14、地址翻译

```
从上面的分析可以看出，分页系统要能够工作的前提是：对于任何一个虚拟页面，系统知道该页面是否在物理内存中，如果在的话，其对应的物理页面是哪个；如果不在的话，则产生一个系统中断（缺页中断），并将该虚页从磁盘转到内存，然后将分配给它的物理页面号返回。也就是说，页面管理系统要能够将虚拟地址转换为物理地址
因此，分页系统的核心是页面的翻译，即从虚拟页面到物理页面的映射。而这个翻译过程由内存管理单元（MMU）完成。MMU接收CPU发出的虚拟地址，将其翻译为物理地址后发送给内存。内存单元按照该物理地址进行相应访问后读出或写入相关数据

内存管理单元对虚拟地址的翻译只是对页面号的翻译，即将虚拟页面号翻译成物理页面号。而对于偏移值，则不进行任何操作。这是因为虚拟页表和物理页表大小完全一样，虚拟页面里的偏移值和物理页面里的偏移值完全一样，因此无须翻译。
那么内存管理单元是通过什么手段完成这种翻译的呢？当然是查页表。对于每个程序，内存管理单元都为其保存一个页表，该页表中存放的是虚拟页面到物理页面的映射。每当为一个虚拟页面寻找到一个物理页面后，就在页表里面增加一个记录来保留该虚拟页面到物理页面的映射关系。随着虚拟页面进出物理内存，页表的内容页不断发生变化。

在程序发出一个虚拟地址给内存管理单元后，内存管理单元首先将地址里面页号部分的字位分离出来，然后判断该虚拟页面是否有效，是否存放在内存，是否受到保护。如果页面无效，即该虚拟页面不存在或没有在内存，也就是说该虚拟页面在物理内存里面没有对应。如果该页面受到保护，即对该页面的访问被禁止，则产生一个系统中断来处理这些特殊情况。对于无效页面访问，需要终止发出该无效访问的进程。对于合法但不在物理内存中的页面，我们通过缺页中断将该虚拟页面放进物理内存。对于受保护的页面，同样终止该进程。
```

15、页表

```
由于页表的特殊地位决定了它由硬件直接提供支持，即页表是一个硬件数据结构
页表在分页内存管理系统的地位十分关键。页表的根本功能是提供从虚拟页面到物理页面的映射。因此，页表的记录条数与虚拟页面数相同
内存管理单元依赖页表来进行一切与页面有关的管理活动。这些活动包括判断某一页面号是否在内存里，页面是否受到保护，页面是否非法空间等。因此，页表除了提供虚拟页面到物理页面的映射外，还记录这些相关信息
```

## 文件原理篇

1、下列步骤描述的是从磁盘上读取一个扇面的过程

```
1）操作系统将要读取的LBA传送给磁盘驱动器并启动读取命令。
2）磁盘驱动器通过将磁头移动到正确的位置，并启动处于指定盘面上的磁头来搜索指定的磁道。在磁头的移动过程中，读取磁头将不断地检查下面的扇面号直到找到所要求的扇面为止。
3）磁盘控制器将扇面数据和ECC信息传送到一个处于磁盘界面里的缓冲区。这里的ECC信息是在数据流动的动态过程中进行计算而得出的。
4）磁盘驱动器向操作系统发出“数据就绪”信号。
5）操作系统从磁盘界面里的缓冲区读取数据，既可以按一个字节一个字节的方式来读取，又可以启动DMA命令来读取。
```

2、磁盘调度算法

```
正如我们前面说过，影响磁盘读写时间的因素有3个：
●寻道时间
●旋转延迟
●数据传输时间
而在这3者中，前两者为机械运动，数据传输主要为电子运动。显然机械运动的速度远低于电子运行的速度。在两个机械运动部分，寻道时间又较长。因此，在上述3个因素中，寻道时间居于支配地位。为了提高磁盘的读写效率，需要降低磁盘的寻道时间，实现的手段则是磁盘调度。磁盘调度的算法主要有以下几种：
●先来先服务FCFS（First Come, First Serve）
●短任务优先STF（Shortest Task First）
●短寻道优先SSF（Shortest Seek First）
●电梯调度ES（Elevator Scheduling）
●提前查看电梯调度ESLA（Elevator Scheduling with Look Ahead）
●单向电梯调度OWES（One Way Elevator Scheduling）
```

3、先来先服务

```
先来先服务是一种自然公平的调度策略。先来后到，谁也没有特权
可是大家都清楚，这种讲究自然公平的策略效率十分低下，因此很少采纳。改进的办法就是对每个磁盘读写任务进行区别对待。
```

4、短任务优先

```
短任务优先就是谁的磁盘读写数据量最少，谁就优先。由于磁盘的访问时间主要取决于寻道和旋转延迟，因此读写的数据量对整个磁盘读写时间的影响并不大。因此这种策略意义不大。
```

5、短寻道优先

```
短寻道优先则考虑当前磁头离谁的数据最近，谁就优先。由于寻道在磁盘访问时间中占的比重最大，此种策略似乎正中要害，能够缩短磁盘访问时间
```

6、电梯调度

```
电梯调度策略很简单，先满足一个方向的所有请求，再满足所有反方向的请求，这样循环往复

对本策略进行仔细分析发现，其运行模式与电梯的运行模式并不完全相同，而是一扫到底。从一个方向扫描到头再反转方向，这也许并不是最有效的。如果一个方向已经没有请求了，我们可以提前调头，而无须等到扫描到末端才进行。这种改进后的算法就是提前查看电梯算法。
```

7、提前查看电梯算法

```
如果一个方向的请求全部满足后，即反转运行。无须扫描到底。这种算法就是每次往某个方向移动时必须确保该方向还有请求未满足。否则即刻调转方向。这样效率将得到提高。

这种正反两个方向交替运动并不一定最优，另外一种改进办法是单向电梯调度，即只向一个方向扫描。当该方向没有剩余请求时，则回到0道，再进行同样的扫描
```

8、固态盘

```
如果我们用与内存相同或相似的存储介质来构建磁盘，不就去除机械运动了吗？而使用与内存介质相同或相仿的存储介质构建的磁盘就是所谓的固态盘（Solid State Disk, SSD）。“固态”的原始意义是半导体驱动器，但在今天的存储工业界已经演化为表示没有机械运动部件的驱动器。由于没有移动的部件，整个驱动器似乎是固定的，因而称为固态盘。目前的固态盘使用的是与内存相同的介质。由于内存有SRAM和DRAM的区别，因此固态盘自然也可以分成这两类。由于没有移动的机械部件，固态盘具有很多普通硬盘不具备的优点：
●可靠性高（到底高多少还有待于进一步的压力试验）。
●没有噪音（由于没有风扇，因此不存在风扇发出的噪音）。
●访问速度高，接近内存的访问速度。
●热耗低于普通硬盘，更省电。
●由于不需要旋转，其启动时间短。
```

9、为什么需要文件系统

```
操作系统为磁盘提供的抽象就是：文件及文件系统，或者说，文件系统就是磁盘的抽象。
```

10、文件系统的目标

```
与内存管理系统类似，文件系统也需要达到两个目的：地址独立和地址保护。地址独立就是一个文件在产生的时候无须担心其存放的磁盘地址，即文件数据的产生与文件将来存放的磁盘地址相互独立。而地址保护则需要对文件的访问进行一定的限制，即不是任何人都可以访问任何文件的。注意，这里的保护与内存地址保护是有区别的。内存管理下地址保护指的是一个进程不能访问另一个进程空间，而这里的保护不是一个文件不能访问另一个文件空间，而是一个文件的访问是有限制的。
```

11、文件类型

```
●目录
●一般文件
●块文件
目录是记录文件的文件，即它的内容是关于别的文件。一般文件用于保存数据。对于一般文件来说，根据其内容的组织方式不同，可以分为两种文件：文本文件和二进制文件。文本文件存放的是没有经过处理的数据，即以ASCII码表示的数据。任何编辑器都可以打开这种文件。二进制文件是经过编码的文件，普通编辑器打不开，必须用专门的应用软件才能打开。另外，加密文件也是二进制文件。块文件既不是关于别的文件，也不是关于用户数据，而是关于输入输出设备的。具体来说，块文件模拟的是输入输出，或者说是为输入输出提供的一个抽象。对于每个输入输出设备，我们以一个文件来表示。需要与该设备发生数据交换时就以该文件来替代。例如，往（Linux、Solaris操作系统下的）lp1文件写数据就相当于使用行式打印机1进行打印。通过块文件，输入输出和文件系统就统一了。也许有读者会问，输入输出设备还能用文件替代？当然。文件系统其实就是为磁盘提供一个抽象。而我们知道磁盘可以看做输入输出设备。既然可以对磁盘提供一个抽象，为什么不能为其他的输入输出提供一种抽象呢？
```

12、地址独立的实现机制：文件夹

```
前面说过，我们可以对文件进行读写等操作。那么给一个文件名，操作系统是怎么知道从什么地方读取文件的内容呢？或者说，文件在磁盘上的什么位置，操作系统是如何知道的呢？这当然需要一个数据结构来记录每个文件在磁盘上的地址，这个数据结构就是文件夹。
文件夹也称为目录夹（folder），它保存的不是用户数据，而是关于文件及文件系统的信息。简单地说，文件夹的角色就是跟踪文件，里面存放的是从文件到文件在磁盘的地址的映射，即“文件名→文件在磁盘上的地址”。文件夹对于文件来说，就相当于动态地址翻译对于虚拟地址的作用，即从虚拟地址到实际地址的一种翻译机制。

这样，当给予一个文件名时，我们从文件夹里可以找到该文件所在的位置，从而发出正确的读取命令。那么文件在磁盘上的地址是什么呢？这就要看文件在磁盘上是如何存放了。如果文件在磁盘上是连续存放的，即一个文件占用一片连续的磁盘空间，则文件在磁盘上的地址就是该文件的第一块数据块所在的磁盘扇面号。当然，文件的存放不只有连续存放一种模式，因此文件在磁盘上的地址还有别的形式，我们稍后解释。但总的一点就是，文件夹应该提供一种找出一个文件所有磁盘块的方法。
既然文件夹存放的是文件名到磁盘地址的映射，那么自然地我们可以以一个简单数组来实现。这个数组是以文本文件存放的，你可以自己写一个程序打开这个文件就可以看到里面的内容。而读取文件夹的内容就变成读取这个简单数组的内容。而这正是shell utility"ls"（UNIX、Linux、Windows Power Shell）和"dir"（Windows）所做的事情。
这里很重要的一点是文件夹本身也是文件。因此，我们可以像对待文件一样对待文件夹：使用同样的存储结构来存放文件夹的数据；文件夹里面的每个记录本身又可以是文件夹。
```

13、文件夹结构

```
由于文件夹里面又可以有文件夹，这样就形成了一个层次结构。这个层次结构的顶端就是根文件夹，也称为根目录
根目录是一个文件系统的总起点，它在操作系统启动的时候加载到内存。从根目录开始，该文件系统里面的所有文件都可以找出来。由于根目录是整个文件系统的源点，如果根目录损坏，则整个文件系统都无法访问，也就说文件系统已经崩溃
```

14、下面我们看一下如何从一个文件名找到其所在的磁盘地址。

```
假定我们要找的文件是：/zou/cs307/file.pdf。这个文件名最前面的代表的就是根目录。因此，我们首先从根目录开始寻找。根目录里面可能保护许多文件和文件夹，其中的一个文件夹就是zou，而根目录里面存放有zou文件夹所在的磁盘地址。我们获得的磁盘地址读取zou的内容（一个文本数组），将其打开。我们发现，打开的zou文件夹里又包括另一个文件夹cs307及其在磁盘上的位置。我们从给出的磁盘位置上读取文件夹cs307的内容（另一个文本数组），发现里面包括一个文件名为file.pdf的文件及其对应的磁盘地址。我们从给出的磁盘地址上就可以读取文件file.pdf的内容。这样从根目录开始，我们需要访问磁盘3次才能得到文件file.pdf的内容。
```

15、相对路径与绝对路径

```
使用相对路径的好处是没有必要寻遍整个目录夹，可以节省磁盘访问次数，从而提高文件访问效率。前面讲过，从根目录开始需要3次磁盘访问才能得到文件file.pdf的内容；但如果在工作目录"zou/cs307/"下直接给出文件名file.pdf，则只需要进行一次磁盘访问即可。因为当前目录的内容是已经打开的，即已经加载到内存的，我们无须磁盘访问即可查看当前目录内容，发现file.pdf的文件及其对应的磁盘地址。我们只需要按照该地址对磁盘进行一个访问即可获得file.pdf的内容。 	
```

16、内存映射的文件访问

```
内存映射的文件访问原理很简单：把需要访问的文件映射到一个进程的虚拟地址内。这样，访问该虚拟地址就相当于访问文件。这样文件访问就变成内存访问
```

17、文件的实现

```
●给文件分配磁盘空间。
●记住这些磁盘空间的位置。
●将文件内容存放在这些空间
给文件分配磁盘空间就是要按照用户要求或文件大小分配恰当容量的磁盘空间，记录这些空间的位置对将来的文件访问至关重要；将文件内容存放到这些空间中则可以通过磁盘本身的驱动器实现。上述3点均需要了解数据在磁盘上的存放方式。
数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有下面两种：
●连续空间存放方式
●非连续空间存放方式
其中非连续空间存放又可以分为链表方式和索引方式
```

18、目录实现：地址独立的实现

```
如果文件是连续存放的，我们只需要文件的第一个数据块的磁盘地址即可，后面的数据块紧接在该数据块后面。这种情况下文件夹里面存放的映射是到I-NODE数据块地址。
如果是链表组织形式，我们只需要文件的第一个数据块磁盘地址即可，后面的数据块可以通过前面数据块里面的指针获得。这种情况下文件夹里面存放的映射也是到I-NODE数据块地址。如果是FAT组织形式，映射仍然保持不变。我们可以从FAT里面找到后继数据块所在的物理磁盘地址。
如果使用的是I-NODE组织形式，我们只需要知道文件对应的顶级I-NODE地址即可。文件的数据块地址可以
从I-NODE里面获得。这种情况下文件夹里面存放的映射是到I-NODE编号。
```

## I/O原理篇

1、对于操作系统设计人员来说，从高层设计来看，关于输入输出我们要问的问题有两个：

```
●输入输出要达到什么目的？
●操作系统是如何实现输入输出功能的？
```

2、输入输出的目的

```
●屏蔽输入输出设备的差异。
●在不同设计之间进行数据表示的转换。
```

## 多核原理篇

